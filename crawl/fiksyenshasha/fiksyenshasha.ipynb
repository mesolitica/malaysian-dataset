{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e383a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "hrefs = []\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a40180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url):\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url,headers = headers)\n",
    "            if r.status_code == 508:\n",
    "                print(r.status_code)\n",
    "                print('error in link, retrying... ', url)\n",
    "                time.sleep(20)\n",
    "                continue\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(1.0)\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    block = soup.find_all('h2',attrs = {\"class\":\"entry-title\"})\n",
    "    if block is None:\n",
    "        return\n",
    "\n",
    "    for link in soup.find_all('h2',attrs = {\"class\":\"entry-title\"}):\n",
    "\n",
    "        href = link.find('a').get('href')\n",
    "        print(href)\n",
    "\n",
    "        hrefs.append(href)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93735f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_worker = 10\n",
    "hrefs = []\n",
    "\n",
    "links = [\"https://fiksyenshasha.com\"]\n",
    "for url in links:\n",
    "    \n",
    "    print(url)\n",
    "    r = requests.get(url,headers = headers)\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    a = soup.find_all('a')\n",
    "    a = [a_.get('href') for a_ in a if a_.get('href')]\n",
    "    pgno = [a_ for a_ in a if 'page' in a_]\n",
    "    max_page = max([int(a_.split('page')[1].replace('/','')) for a_ in pgno])\n",
    "    print(max_page)\n",
    "    for i in tqdm(range(1, max_page + 1, max_worker)):\n",
    "        aranged = np.arange(i, i + max_worker)\n",
    "        urls = [f'{url}/page/{a}' for a in aranged]\n",
    "        with ThreadPoolExecutor(max_workers=max_worker) as executor:\n",
    "            futures = {executor.submit(crawl, url): url for url in urls}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec63a23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e99b2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = list(set(hrefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8a68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fiksyenshasha-links.json', 'a') as f:\n",
    "    json.dump(hrefs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f7d7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fiksyenshasha-links.json') as f:\n",
    "    hrefs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4c017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(x):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'} # This is chrome, you can set whatever browser you like\n",
    "    comments = []\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(x, headers=headers)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(5.0)\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    try:\n",
    "        headline = soup.find('h1', class_=\"entry-title\").text\n",
    "        h = soup.find('div', attrs = {\"class\":\"entry-content\"})\n",
    "        p = [p.text for p in h.find_all(\"p\") if len(p.text.split(\" \")) > 1 and 'fiksyenshasha.com/submit' not in p.text ]\n",
    "    except Exception as e:\n",
    "        print('error in link:'+ x)\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    comment_list = soup.find('div',attrs = {\"class\":\"comments-area\"})\n",
    "    if comment_list:\n",
    "        c = comment_list.find_all('div',attrs = {\"class\":\"comment-content\"})\n",
    "        for j in c:\n",
    "            comments.extend([c_.text for c_ in j.find_all(\"p\") if len(c_.text) > 1])\n",
    "    \n",
    "    data = {'url': x, 'headline': headline, 'content': p, 'comment': comments}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26c4573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                           | 2224/7006 [02:29<07:46, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='fiksyenshasha.com', port=443): Max retries exceeded with url: /saka-harimau/ (Caused by SSLError(SSLError(1, '[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1131)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7006/7006 [09:00<00:00, 12.97it/s]\n"
     ]
    }
   ],
   "source": [
    "max_workers = 20\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(process_url, x) for x in hrefs]\n",
    "    \n",
    "    for future in tqdm(futures, total=len(hrefs)):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            with open('fiksyenshasha.jsonl', 'a',encoding='utf8') as f:\n",
    "                json.dump(result, f,ensure_ascii=False)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b39c2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://fiksyenshasha.com/pengalaman-di-asrama-ketika-pelajar-lain-bercuti/',\n",
       " 'headline': 'Pengalaman di Asrama Ketika Pelajar Lain Bercuti',\n",
       " 'content': ['asalamualaikum shahshaâ€¦',\n",
       "  'saya adalah salah seorang pembaca setia page fiksyen Shasha.. memandangkan dah ramai share pengalaman masing-masing, saya pun ingin berkongsi kisah saya ni.. tidak la terlalu seram tapi ianya cukup membuatkan saya tidak dapat tidur lena malam tu..',\n",
       "  'Kisah ni berlaku pada tahun 2013, ketika itu saya mendapat tawaran di sebuah kolej untuk kursus Safety lepasan diploma.. sebab dah saya bosan duduk dirumah, saya terima terima saja tawaran tersebut. lagipun kursus ni jangka pendek, 6 bulan sahaja. selepas membuat pendaftaran, kami ditempatkan diasrama bangunan lama yang sudah usang..',\n",
       "  'Memandangkan kursus ini pendek maka tidak terdapar banyak bilik kosong yg disediakan oleh pihak berwajib, jadi saya tinggal di dorm bersama junior2 sijil dan diploma di tingkat 1.. keanehan pertama yg saya lihat, tak ramai student yang ada pada petang jumaat itu, ada beberapa teman sibuk mengemas untuk pulang ke rumah.',\n",
       "  'tiba-tiba muncul warden asrama dari muka pintu, â€œAwak nak tidur sini malam ni atau trus atau mahu pulang seperti yang lain-lain?â€',\n",
       "  'pertanyaan warden buat saya bertambah pelik.. melihat keanehan teman lain yang sibuk berkemas, saya bercadang untuk pulang dan tinggalkn barang2 shaja dalam almari. (Memandangkan asrama tidak jauh dari rumah)',\n",
       "  'pada hari ahad saya pula datang semula ke asrama, dan saya berkenalan dengan beberapa rakan rakan yang mengambil kursus berlainan dengan kos dengan saya. Pada sesi perkenalanan, ada yang bercerita mengapa asrama dikosongkan selama 2 hari terjawab.. disebabkan ramai pelajar kursus akan masuk, pelajar yang kemasukan lebih awal dr saya, yang duduk di dorm tingkat atas sekali nak dijadikan cerita telah diganggu.. jadi sesi â€˜pmbersihanâ€™ dilakukan pada 2 hari berturut -turutâ€¦ namun, kejadian itu masih lagi berlaku.',\n",
       "  'Selepas 2 minggu, semasa saya pulang dr kolej, saya dan rakan-rakan perempuan melihat ramai rakan-rakan lelaki dari asrama sebelah sibuk mengemas untuk berpindah.. Mereka mengatakan bahawa sudah tidak tahan dengan gangguan dan sudah mencari rumah sewa berdekatan dengan kolej..',\n",
       "  'mereka telah diganggu dengan teruk ketika minggu pertama lagiâ€¦ pada malam pertama mereka tidur di dorm salah seorang mengadu diganggu. katilnya tiba-tiba bergoncang kuat, ada yang mendengar suara perempuan, dan ada juga melihat rmbut pnjng terjurai dari atas katil ada jugak bercerita melihat kanak -kanak seperti toyol.',\n",
       "  'Pulang ke asrama, kami dimaklumkan pelajar-pelajar diploma dan sijil akan cuti sem jadi tinggallah kami dalam 8 orang.. maka dengan automatiknya dorm tingkat atas kosong. keseraman pun bermula.',\n",
       "  'Suatu malam, bahang panas dalam dorm terasa kuat dan tiba-tiba bekalan eletrek terputus. Saya dah mula panik lalu terjaga. melihat kawan di sebelah masih terlena, saya memusing ke arahnya.. keadaan malam itu sangat menakutkan, macam-macam bunyi saya dengar. Seolah-olah ada yang sedang bermain dalam gelap.',\n",
       "  'Entah macam mana, kepala saya makin berat berat. Rasa ade yang tekan banyak kali. mulut dah terkumat kamit membaca ayat-ayat suci. saya mula membebel dalam hati.. eh, die main kepala la pulakkk',\n",
       "  'saya memejam mata rapat-rapat . Takut sangat kalau ternampak benda tu depan mata. Selang beberapa minit, dengan kepala yang berdenyut-denyut saya membuka mata perlahan-lahan.. gelapnya!!! sambil melilau mata melihat sekeliling, kedengaran bunyi dengungan dalam bilik tu.. dan satu suara kanak-kanak menyapa:',\n",
       "  'â€œJom!! Kita pergi main!!â€',\n",
       "  'Saya dah panik masa tu.. takut yang teramat sangat.. walaupun suara tu hanya berbunyi sekali memang cukup buat saya meremang bulu roma. Saya terus pejam mata rapat-rapat.. boleh rasa dia ada dekat dengan saya.. dalam masa yang sama boleh rasa macam dia gletek kakiâ€¦ eeee pergilah main jauh-jauh.. saya bisik dalam hati..',\n",
       "  'sedar-sedar azan subuh berkumandang, tiba-tiba.. tuppp!! bunyi kipas dan lampu terbuka kembaliâ€¦ saya terkebil-kebil melihat sekeliling.. melihat rakan-rakan lain sedang enak diulit mimpi.. peluh basah tak yah cakap.. menitik macam baru lari maraton..',\n",
       "  'salah seorang dari kami ada terbangun pergi ke tandas lalu saya menegurnya , â€œada dengar apa-apa tak malam tadi?â€\\nDia dah pandang saya pelik. â€œtak dengar pun kak, cuma blackout je malam tadiâ€¦ â€\\ntanpa banyak tanya saya bingkas bangun mengambil wuduk lalu menunaikan solat subuh.\\nDalam hati masih tertanya-tanya apakah benda tu sebenarnya.',\n",
       "  'Pagi tu sedang bersarapan di kolej, saya bercerita pengalaman saya bersama rakan-rakan lain. salah seorang dari kami mengatakan memang ada kanak-kanak kecil yang berlegar di dorm kami, dia pernah nampak ketika lewat malam. Benda tu pun tak pernah kacau dia cuma menampakan dirinya sambil tersenyum. ?',\n",
       "  'kata mereka mujurlah kanak-kanak. kalau cik ponti yg muncul macam kes di dorm lelaki boleh demam panas jadinya.',\n",
       "  'Kini, bangunan asrama tersebut mula dikosongkan sejak tahun 2015. Kisah seram di situ terbuku begitu sahaja.',\n",
       "  'mohon shasha hidekan nama profile saya. terima kasih..'],\n",
       " 'comment': ['test',\n",
       "  'xtaw nak ckp pe..cam kureng sikit citenye',\n",
       "  'hmmmmm',\n",
       "  'hurmm',\n",
       "  'Baru nk feel seram tp mcm pancit tetibe hehe, pepun best story ðŸ‘',\n",
       "  'Ok laâ€¦.2/5 bintang',\n",
       "  'So so',\n",
       "  'Best bro cite kau ni memang the best story i ever read good job !!!',\n",
       "  'Kemain semangat kau',\n",
       "  'Tahap keseraman not bad tapi ada sesetengah ayat kena letak tanda koma . So, bila kau tak letak, jadi celaru sikit. By the way, story kau best .',\n",
       "  'Not bad',\n",
       "  'Bolehlah',\n",
       "  'Mcm prnh terbaca cerita ne..tp ntah d manaâ€¦',\n",
       "  'Penceritaan mudah difahamiâ€¦boekkkâ€¦ðŸ˜„ðŸ‘ŒðŸ‘ŒðŸ‘Œ',\n",
       "  'seram nyerâ€¦',\n",
       "  'Bolehlaâ€¦ Boring ni smpai cari kisah lama shashaâ€¦ Huhu',\n",
       "  'tak boleh ke sape2 yg kena kacau tu espeseli kt asrama ni, buat bergilir2 baca quran marathon sblm decide pindah kt lain. mesti student ni ada yg kelas stat lambat ataupun tidur awal ke. so bagi2 la, 12-2pg 3 org ni baca. 2-4 pg group lain pula baca. 4-6pg group lain plak. alang2 tu terus niat khatam quran sama2.',\n",
       "  'Cite kau ni menarik cuma x sampai klimaks lagiâ€¦.lain kali belajar cara penggunaan kata']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_url(\"https://fiksyenshasha.com/pengalaman-di-asrama-ketika-pelajar-lain-bercuti/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
